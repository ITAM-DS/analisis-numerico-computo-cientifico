{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(INTROOPTCODIGO)="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Introducción optimización de código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Notas para contenedor de docker:\n",
    "\n",
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "`docker run --rm -v <ruta a mi directorio>:/datos --name jupyterlab_optimizacion_2 -p 8888:8888 -p 8787:8787 -d palmoreck/jupyterlab_optimizacion_2:3.0.0`\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "`docker stop jupyterlab_optimizacion_2`\n",
    "\n",
    "Documentación de la imagen de docker `palmoreck/jupyterlab_optimizacion_2:3.0.0` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion_2).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Al final de esta nota el y la lectora:\n",
    ":class: tip\n",
    "\n",
    "* Conocerá razones del por qué implementaciones de algoritmos son ineficientes a diferentes niveles. Uno es al nivel de lenguajes utilizados. Otro es al nivel de componentes de un sistema computacional.\n",
    "\n",
    "* Conocerá herramientas para analizar y escribir programas para un alto rendimiento.\n",
    "\n",
    "* Conocerá rediseños que se han hecho a las unidades computacionales de un sistema computacional para resolver *bottlenecks*.\n",
    "\n",
    "* Conocerá la jerarquía de almacenamiento en el sistema de memoria de un sistema computacional.\n",
    "\n",
    "* Conocerá la diferencia entre programas secuenciales y en paralelo.\n",
    "\n",
    "* Aprenderá una metodología y enfoques utilizados para escribir programas en paralelo.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de los métodos o algoritmos en el contexto de grandes cantidades de datos o *big data* es crítica al ir a la práctica pues de esto depende que nuestra(s) máquina(s) tarde meses, semanas, días u horas para resolver problemas que se presentan en este contexto. En este contexto la [optimización de código o de software](https://en.wikipedia.org/wiki/Program_optimization) nos ayuda a la eficiencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temas a considerar para escribir un programa de máquina de alto rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tener un alto *performance* en un programa de máquina, deben considerarse las siguientes preguntas:\n",
    "\n",
    "* ¿Qué tanto aprovecha mi programa aspectos como ***data reuse*** y ***data locality***? \n",
    "\n",
    "La respuesta nos lleva a pensar en el número de instrucciones por ciclo y el número de ciclos que realiza el procesador. Entiéndase un ciclo por los pasos de leer una instrucción, determinar acciones a realizar por tal instrucción y ejecutar las acciones, ver [liga](https://en.wikipedia.org/wiki/Instruction_cycle).\n",
    "\n",
    "* ¿Cómo es mi ***data layout*** en el almacenamiento? (forma en la que están almacenados o dispuestos los datos)\n",
    "\n",
    "Dependiendo de la respuesta podemos elegir una arquitectura de computadoras u otra y así también un algoritmo u otro.\n",
    "\n",
    "* ¿Cuánto ***data movement*** o ***data motion*** realiza mi programa? (flujo de datos entre los distintos niveles de jerarquía de almacenamiento o entre las máquinas en un clúster de máquinas)\n",
    "\n",
    "La respuesta implica analizar el tráfico de datos entre las **jerarquías de almacenamiento** (o máquinas si estamos en un clúster de máquinas) y potenciales ***bottlenecks***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herramientas que tenemos a nuestra disposición para analizar y escribir programas de máquina para un alto rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vectorización que pueden realizar los procesadores.\n",
    "\n",
    "* Perfilamiento de código para lograr la eficiencia deseada. \n",
    "\n",
    "* Programación en lenguajes compilados en lugar de intérpretes (o combinando intérpretes con lenguajes compilados)\n",
    "\n",
    "* Conocimiento de los propósitos con los que fueron diseñados los procesadores para explotar su capacidad. Aquí decidimos si usamos **código secuencial** o **código en paralelo**.\n",
    "\n",
    "...además necesitamos conocer las diferentes **arquitecturas** que pueden utilizarse para cómputo en paralelo.\n",
    "\n",
    "* ¿Alguien ya resolvió mi *bottleneck*?\n",
    "\n",
    "* Experiencia en el lenguaje de programación seleccionado. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorización, [BLAS: Basic Linear Algebra Subprograms](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) y el uso del caché eficientemente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un poco de historia y generalidades del sistema en una computadora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las componentes fundamentales de un sistema en una computadora pueden simplificarse en:\n",
    "\n",
    "* Unidades computacionales. En éstas unidades nos interesa la pregunta ¿cuántos cálculos pueden realizar por segundo?\n",
    "\n",
    "* Unidades de memoria. En éstas unidades nos interesa la pregunta ¿cuántos datos pueden alojar y qué tan rápido puede leerse desde y escribirse hacia las distintas jerarquías?\n",
    "\n",
    "* Conexiones entre las unidades anteriores. Nos interesa ¿qué tan rápido pueden moverse datos de un lugar a otro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Ver [liga](https://es.wikipedia.org/wiki/Caché) para información sobre cachés tipo L.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta simplificación tenemos como ejemplo a la CPU como unidad de cómputo conectada tanto a la RAM y a un disco duro como dos unidades de memoria y un *bus* que provee las conexiones entre estas partes. Otro ejemplo es considerar que la CPU tiene diferentes unidades de memoria en ella: los cachés tipo L1, L2, L3 y L4 conectadas a la CPU a través de otro *bus*. También la GPU es ejemplo de una unidad de cómputo conectada a una unidades de memoria como RAM y cachés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un dibujo simplificado y basado en una arquitectura de computadoras con nombre [Von Neumann](https://en.wikipedia.org/wiki/Von_Neumann_architecture) que nos ayuda a visualizar lo anterior en la **CPU** es el siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/txsj5mzxyajbypa/von_Neumann.png?dl=0\" heigth=\"500\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La **memoria principal** es una colección de ubicaciones que almacenan datos e instrucciones. Cada ubicación consiste de una dirección (*address*) que se utiliza para accesar a la ubicación y a sus contenidos.\n",
    "\n",
    "* La CPU está dividida en la **unidad de control y la unidad aritmética y lógica**. Aquí encontramos *registers* que son áreas o ubicaciones de almacenamiento (de datos, direcciones de memoria e información del estado de ejecución de un programa) de rápido acceso.\n",
    "\n",
    "* La **interconexión** o *bus* ayuda a la transferencia de datos e instrucciones entre la CPU y la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* En el dibujo no se está presentando los dispositivos de *input* y *output* pero sí aparecen en la arquitectura de Von Neumann.\n",
    "\n",
    "* También no se presentan en el dibujo unidades de almacenamiento como los discos duros pero también aparecen en la arquitectura de Von Neumann. Los discos duros se consideran dentro de las unidades de memoria y la CPU se conecta a ellos mediante un *bus*.\n",
    "\n",
    "* Si los datos se transfieren de la memoria a la CPU se dice que los datos o instrucciones son leídas y si van de la CPU a la memoria decimos que son escritos a memoria.\n",
    "\n",
    "* La separación entre la memoria y la CPU genera lo que se conoce como **Von Neumann *bottleneck*** y tiene que ver con la lectura/escritura y almacenamiento de datos e instrucciones. La interconexión determina la tasa a la cual se accede a éstos.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unidades de memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su objetivo es el almacenamiento de bits de información. Como ejemplos tenemos la memoria RAM, discos duros o el caché. La principal diferencia entre cada tipo de unidad de memoria es la velocidad a la que pueden leer/escribir datos. Ésta velocidad depende enormemente de la forma en que se leen los datos. Por ejemplo, la mayoría de las unidades de memoria tienen un mejor *performance* al leer un gran pedazo de información que al leer muchos pedacitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Desde el punto de vista de los lenguajes de programación como Python o R, un resultado del manejo automático de memoria en estos lenguajes, es la fragmentación de datos o ***data fragmentation*** que surge al no tener bloques contiguos de memoria. Esto causa que en lugar de mover todo un bloque contiguo de datos en una sola transferencia a través del *bus* se requieran mover pedazos de memoria de forma individual lo que causa un mayor tiempo de lectura.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las unidades de memoria tienen latencia que típicamente cambia dependiendo de una jerarquía de almacenamiento mostrada en el  dibujo siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Entiéndase por latencia el tiempo que le toma a la unidad o dispositivo para encontrar los datos que serán usados por el proceso.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jerarquías de almacenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/ahxsnpgp4rjdvw3/jerarquias_de_almacenamiento.png?dl=0\" heigth=\"500\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dibujo anterior se representan típicos dispositivos de almacenamiento en una máquina. La capacidad de almacenamiento **disminuye** conforme nos movemos hacia arriba en el dibujo: mientras que en disco podemos almacenar terabytes de información, en los *registers* sólo podemos almacenar bytes o kilobytes. Por el contrario, la velocidad de lectura/escritura **disminuye** conforme nos movemos hacia abajo: la lectura y escritura en disco es órdenes de veces más tardado que en los *registers* (que físicamente están en el procesador)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caché\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las técnicas que tenemos a nuestro alcance para que un algoritmo pueda aprovechar el **data layout** de la información se encuentra el *caching*: el eficiente uso del caché. \n",
    "\n",
    "El caché es una memoria que está físicamente localizada más cercana a los registers del procesador para almacenar datos e instrucciones por lo que pueden ser accesados en menor tiempo que en otras unidades de memoria (como la RAM).\n",
    "\n",
    "El caché se diseñó para resolver el Von Neumann *bottleneck* al existir un límite de tasa de transferencia entre la memoria RAM y el procesador (CPU o GPU). Si pudiéramos mover datos de una forma infinitamente rápida, no necesitaríamos al caché pues el procesador podría obtener los datos en cualquier instante, en esta situación no existiría tal bottleneck.\n",
    "\n",
    "Aunque no tenemos en nuestros lenguajes de programación instrucciones del tipo \"carga los datos en el caché\" podemos usar los principios de **localidad** y **temporalidad** para mejorar la eficiencia de nuestros algoritmos. Los principios de localidad y temporalidad consisten en que el sistema de memoria tiende a usar los datos e instrucciones que físicamente son cercanos (localidad) y los datos e instrucciones que recientemente fueron usados (temporalidad).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo funciona el acceso a la memoria en un sistema de computadora?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el procesador requiere un conjunto de datos para ejecutar instrucciones, el sistema de memoria carga un bloque de datos (aunque pueden ser también instrucciones), conocido como ***cache blocks*** o ***cache lines*** para que el procesador opere en ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En C al declarar un arreglo con la línea: `float z[20];` se le solicita al sistema de memoria que se alojen $20$ bloques contiguos de ubicaciones de memoria en la RAM, esto es: la ubicación para el almacenamiento de `z[1]` está inmediatamente después de la de `z[0]`. Si además tenemos un programa como el siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "...\n",
    "float z[20];\n",
    "float sum=0;\n",
    "int i=0;\n",
    "for(i=0;i<20;i++)\n",
    "   sum+=z[i];\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y nuestro cache line permite almacenar $16$ floats, entonces el sistema de memoria leerá los datos `z[0],...,z[15]` de la RAM al caché y el procesador realizará la suma.\n",
    "\n",
    "Posteriormente el procesador (que en este caso es la CPU) al accesar a los datos checa primero el caché, si las encontró se le conoce como ***cache hit***, si no lo encontró sería un ***cache miss*** y el sistema de memoria tendría que leer nuevamente desde la RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C almacena los arreglos de dos dimensiones en una forma ***row major***, esto es, aunque en papel representamos tales arreglos como un bloque rectangular, en la implementación en este lenguaje se están almacenando como un arreglo de una dimensión: el renglón $0$ es almacenado primero, a continuación el renglón $1$ y así sucesivamente.\n",
    "\n",
    "Observemos los siguientes códigos que realizan una multiplicación **secuencial** entre una matriz `A` y un vector `x` para obtener al vector `y`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo: multiplicación matriz vector secuencial**\n",
    "\n",
    "\n",
    "```C\n",
    "double A[MAX][MAX], x[MAX], y [MAX]; //MAX es un valor constante definido previamente\n",
    "...\n",
    "\n",
    "//bloque de código para inicializar A,x\n",
    "//bloque de código para inicializar y con ceros\n",
    "\n",
    "//Algoritmo 1:\n",
    "\n",
    "for(i=0;i<MAX;i++)\n",
    "    for(j=0;j<MAX;j++)\n",
    "        y[i]+=A[i][j]*x[j];\n",
    "\n",
    "//volver a asignar a y con ceros\n",
    "\n",
    "//Algoritmo 2:\n",
    "\n",
    "for(j=0;j<MAX;j++)\n",
    "    for(i=0;i<MAX;i++)\n",
    "        y[i]+=A[i][j]*x[j];\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que `MAX=4` y los elementos de `A` están almacenados en memoria como sigue:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/rgjh4pv0o1kbe24/ejemplo_cache.png?dl=0\" heigth=\"500\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para simplificar el siguiente análisis supóngase que:\n",
    "\n",
    "* Ninguno de los elementos de `A` están en el caché al iniciar el par de loops.\n",
    "\n",
    "* Un *cache line* consiste de $4$ elementos de `A` y `A[0][0]` es el primer elemento del *cache line*.\n",
    "\n",
    "* Cada *cache line* le corresponde una única úbicación en el caché al que será asignado.\n",
    "\n",
    "* El caché sólo puede almacenar $4$ elementos de `A` o un *cache line*.\n",
    "\n",
    "Entonces para el algoritmo $1$ se tiene que la CPU y el sistema de memoria:\n",
    "\n",
    "1) La CPU requiere `A[0][0]` que no se encuentra en el caché por lo que tenemos un *cache miss* y el sistema de memoria lee de RAM el *cache line*: `A[0][0] A[0][1] A[0][2] A[0][3]` y al estar en caché la CPU puede operar con `A[0][0]`.\n",
    "\n",
    "2) La CPU requiere `A[0][1]` que sí se encuentra en el caché por lo que tenemos un *cache hit* y la CPU opera con éste dato. Posteriormente la CPU requiere `A[0][2]`, `A[0][3]` y `A[0][4]` que se encuentran en caché y se tienen otros tres *cache hits*.\n",
    "\n",
    "3) La CPU requiere `A[1][0]` que resulta en un *cache miss* y el sistema de memoria lee de RAM el *cache line*: `A[1][0] A[1][1] A[1][2] A[1][3]` y al estar en caché la CPU puede operar con `A[1][0]`.\n",
    "\n",
    "...\n",
    "\n",
    "Finalmente para el algoritmo $1$ tenemos $4$ cache misses, uno por cada renglón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "¿Cuál es el número de cache misses para el algoritmo 2?.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mayor número de *cache misses* incrementa el tiempo de ejecución de las instrucciones por el procesador pues no solamente el procesador espera mientras se transfieren los datos de la RAM hacia el caché sino también se interrumpe el flujo de la ejecución del *pipeline*. Por ello es importante que los algoritmos trabajen con un buen ***data layout*** de la información en memoria y utilicen el ***data reuse*** y ***data locality***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* El *pipelining* es un mecanismo utilizado por un procesador para la ejecución de instrucciones. Obstáculos al *pipelining* se encuentran los *cache misses* o el llamado *mispredicted branching*. El *branch prediction*, relacionado con el *branching* en un código (para el *branching* piénsese por ejemplo en una línea de código del tipo `if...then`), es otro mecanismo del procesador para tratar de predecir la siguiente instrucción a ejecutar y cargar las porciones relevantes de memoria en el caché mientras se trabaja en la instrucción actual. El procesador al toparse con un *branching* en el código trata de hacer una suposición de qué dirección se tomará en el *branching* y precargar las instrucciones relevantes, si falla tiene ***branch-misses***. Aunque también son importantes estos aspectos al considerar la implementación de un algoritmo, la herramienta más rápida que tenemos para resolver los *bottlenecks* en este contexto, son trabajar en la localidad y temporalidad de los datos.\n",
    "\n",
    "* Un factor que incrementa el número de *cache-misses* es la fragmentación de datos, ver [Fragmentation](https://en.wikipedia.org/wiki/Fragmentation_(computing)). La fragmentación incrementa el número de transferencias de memoria hacia la CPU y además imposibilita la vectorización porque el caché no está lleno. El caché puede llenarse sólo al tener bloques contiguos de memoria alojados para los datos (la interconexión o *bus* sólo puede mover *chunks* de memoria contigua). Python en su implementación común [CPython](https://en.wikipedia.org/wiki/CPython), tiene ***data fragmentation*** por ejemplo al usar listas. Las listas de Python alojan locaciones donde se pueden encontrar los datos y no los datos en sí. Al utilizar tales estructuras para operaciones matriciales el *runtime* de Python debe realizar *lookups* por índices y al no encontrarse de forma contigua los datos, el *overhead* en la transferencia de datos es mayor lo que causa que se tengan mayor número de *cache-misses* y que los *cores* tengan que esperar hasta que los datos estén disponibles en el caché. Por lo anterior las listas no se recomiendan para operaciones vectoriales o matriciales pero sí se utilizarían en casos como almacenar diferentes tipos de valores.\n",
    "\n",
    "* En Python se tiene el paquete de [numpy](https://numpy.org/) para almacenamiento de bloques de memoria contiguos de arreglos y uso de la capacidad de la CPU para operaciones en un modo vectorizado. Sin extensiones a Python con paquetes como `numpy` no sería posible en este lenguaje aprovechar la vectorización (capaz de realizar un procesador actual) ni alojar bloques de memoria contiguos. El no soporte para operaciones vectorizadas tiene que ver con que el [bytecode](https://en.wikipedia.org/wiki/Bytecode) de Python no está optimizado para vectorización. En el caso del alojamiento de bloques de memoria contiguos, Python es un *garbage-collected language* que permite que la memoria sea automáticamente alojada y liberada. No obstante tal característica causa problemas del tipo ***memory fragmentation*** que afecta la transferencia al caché de datos **usables** o **relevantes** para las operaciones (ver ejemplo del algoritmo 2 anterior).\n",
    "\n",
    "* Para monitoreo de número de instrucciones por ciclo, número de ciclos por segundo, *branch misses, cache references* (o *hits*) y *misses* se recomiendan las herramientas de [perf](https://en.wikipedia.org/wiki/Perf), [valgrind](https://valgrind.org/), ver también: [Valgrind](https://en.wikipedia.org/wiki/Valgrind).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interconexión, *bus* o capas de comunicación y transferencia de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay distintos *bus* que permiten la comunicación entre las unidades computacionales y las de memoria:\n",
    "\n",
    "* El *backside bus* que permite la conexión entre el caché y el procesador. Tiene la tasa de transferencia de datos más alta.\n",
    "\n",
    "* El *frontside bus* permite la conexión entre la RAM y los L's cachés. Mueve los datos para ser procesados por el procesador (CPU o GPU) y mueve los datos de salida (resultados) entre estas regiones de memoria.\n",
    "\n",
    "* El *external bus* cuya acción se realiza en los dispositivos de hardware como los discos duros y tarjetas de memoria hacia la CPU y el sistema de memoria. Este *bus*  típicamente es más lento que el *frontside bus*.\n",
    "\n",
    "Entonces los datos se mueven del disco hacia la RAM con el *external bus*, luego de la RAM hacia el caché vía el *frontside bus* y finalmente del caché hacia la CPU con el *backside bus*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* La GPU está conectada en un dispositivo periférico y se comunica através del *PCI bus*, (ver [PCI](https://en.wikipedia.org/wiki/Conventional_PCI)) el cual es más lento que el *frontside bus*. Como resultado, la transferencia de datos hacia la GPU y fuera de ésta es una operación costosa. Un diseño que atiende este problema es tener tanto a la CPU como a la GPU en el *frontside bus* para reducción de costos de transferencia hacia la GPU para grandes cantidades de información.\n",
    "\n",
    "* Otra capa de comunicación en un sistema de computadora es la red o *network*. Un dispositivo de red puede conectarse a una unidad de memoria u a otra unidad de computación. Típicamente la comunicación por red es mucho más lenta que las comunicaciones con el *backside, frontside, external bus*.\n",
    "\n",
    "* La propiedad principal de un *bus* es su velocidad: ¿cuántos datos pueden moverse en un periodo de tiempo? Esta propiedad se obtiene combinando el *bus width* entendido como ¿cuántos datos se pueden mover en una transferencia? (físicamente se puede observar por el número de cables del *bus*) y el *bus frequency* ¿cuántas transferencias se pueden hacer por segundo? (físicamente se ve en la longitud de los cables que unen a las unidades de cómputo o memoria). \n",
    "\n",
    "* Es importante notar que el movimiento de los datos en una transferencia siempre es secuencial: un pedazo de datos es leído de memoria y es movido a otro lugar: no es posible leer un pedazo de datos y moverlo a distintos lugares o leer divisiones del pedazo de datos que estén en distintos lugares.\n",
    "\n",
    "* Un *bus width* grande ayuda a la vectorización pues en una sola transferencia se mueven los datos importantes. Un *bus frequency* alto puede ayudar al código a realizar una gran candidad de lecturas de diferentes lugares de la memoria. Depende qué operación es la que se desea realizar lo que en un caso u otro convendrá. Por ejemplo, si el problema a resolver se relaciona con la cantidad de lecturas que se deben hacer, podríamos tener un *bus frequency* alto y un *bus width* pequeño para resolver un *bottleneck* de lecturas.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unidades computacionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Para referencias de instrucciones por ciclo (IPC) ver [liga](https://en.wikipedia.org/wiki/Instructions_per_cycle) y número de ciclos por segundo ver [liga](https://en.wikipedia.org/wiki/Clock_rate).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea una CPU o una GPU, las unidades computacionales toman como input un conjunto de bits (que representan números por ejemplo) y producen otro conjunto de bits (por ejemplo la suma de los números). El performance de éstas unidades se mide en **instrucciones por ciclo** y en **ciclos por segundo**, nombrado *clock rate* o *clock speed*. La IPC puede incrementarse vía la **vectorización**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre los rediseños que se han hecho para las unidades computacionales de un modelo clásico de Von Neumman con el objetivo de resolver los *bottlenecks*, mejorar la velocidad y el *performance* se encuentran:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Múltiples CPU's o cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incrementar el *clock speed* en una unidad computacional hace más rápido a un programa y también es importante la medida de IPC. La IPC se puede incrementar vía la **vectorización** y es típico en procesadores que soportan las instrucciones llamadas ***Single Instruction Multiple Data*** (SIMD). La vectorización consiste en que dados múltiples datos, el procesador puede trabajar sobre ellos en un instante o tiempo (ejecución en **paralelo**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/mpfk9xmtq9fm7vm/SIMD.png?dl=0\" heigth=\"450\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "El término *core* hoy en día lo usamos como sinónimo de procesador.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Este tipo de procesadores reemplazaron al modelo de Von Neumann clásico ***Single Instruction Single Data*** (SISD): \n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/bdx27axhnl3ug5n/SISD.png?dl=0\" heigth=\"300\" width=\"300\">\n",
    "\n",
    "en el que un conjunto de datos se procesaban en un tiempo determinado y no de forma simultánea o en **paralelo**. Así, se transitó de un diseño de hardware secuencial hacia un hardware paralelo.\n",
    "\n",
    "* Un ejemplo de procesadores SIMD son los procesadores vectoriales o en arreglo, ver [liga](https://en.wikipedia.org/wiki/Vector_processor).\n",
    "\n",
    "* En la práctica se ha visto que simplemente añadir más CPU's o cores al sistema **no siempre** aumenta la velocidad de ejecución en un programa. Existe una ley que explica lo anterior, **la ley de Amdahl**, la cual indica que si un programa está diseñado para ejecutarse en múltiples cores y tiene algunas secciones de su código que pueden sólo ejecutarse en un core, entonces éste será el *bottleneck* del programa. Por ejemplo, si tuviéramos que realizar una encuesta que tarda $1$ min a $100$ personas y tenemos una sola persona, entonces nos tardaríamos $100$ minutos (proceso serial). Si tenemos a $100$ personas entonces nos tardaríamos $1$ minuto en completar todas las encuestas (proceso en paralelo). Pero si tenemos más de $100$ personas, entonces no nos tardaremos menos de $1$ minuto pues las personas \"extras\" no podrán participar en realizar la encuesta. En este punto la única forma de reducir el tiempo es reducir el tiempo que le toma a una persona encuestar a otra (esta es la parte secuencial del programa). \n",
    "\n",
    "* Los sistemas SISD, SIMD y ***Multiple Instruction Multiple Data*** (MIMD), presentado a continuación:\n",
    "\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/ddze2xuzwn9bh6h/MIMD.png?dl=0\" heigth=\"500\" width=\"500\">\n",
    "\n",
    "son parte de la taxonomía de Flynn (ver [liga](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy)) que clasifica a los sistemas dependiendo del número de stream de datos e instrucciones que puede procesar. Ejemplos de sistemas MIMD son máquinas multicore y clústers de máquinas. \n",
    "\n",
    "* En la taxonomía de Flynn hay una división más, la del sistema ***Simple Program Multiple Data*** (SPMD) en el que un mismo programa se ejecuta en múltiples datos, éste sistema lo encontramos en la GPU por ejemplo.\n",
    "\n",
    "* Hoy en día la industria continúa desarrollando y creando procesadores capaces de ejecutar instrucciones basadas en operaciones vectorizadas. Ver por ejemplo [Streaming SIMD Extensions 2: SSE2](https://en.wikipedia.org/wiki/SSE2) y [Advanced Vector Extensions: AVX](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions).\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Threading* o *Hyperthreading*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra funcionalidad que se les añadió a los procesadores para incrementar la velocidad de ejecución de un **proceso** y resolver el *bottleneck* de Von Neumann fue la capacidad de crear hilos, ***threads***, de ejecución en un programa contenidos en un proceso, el llamado *threading* o *hyperthreading* en una CPU o en un core. Básicamente el *threading* permite la ejecución de más de una instrucción en un mismo core \"virtualizando\" un procesador adicional (el sistema operativo \"cree\" que en lugar de haber un core hay dos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definiciones\n",
    "\n",
    "Un proceso es una instancia de un programa que se ejecuta en el procesador y está compuesto por elementos como por ejemplo los bloques de memoria que puede utilizar (los llamados *stack* y *heap*) e información de su estado, entre otros.\n",
    "\n",
    "Un *thread*, al igual que un proceso, es una instancia de un programa, se ejecuta en el procesador pero está contenido en el proceso del que salió. Al estar contenido en el proceso, comparte elementos de éste, tienen distinto *stack* de memoria (variables locales creadas en funciones) y en sistemas *multicore* es posible definir variables que sean accesadas por todos los *threads* (variables globales).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La creación de threads a partir de un proceso se le llama *fork* y su unión al proceso se le llama *join*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/0vnjfdk7fo62m8h/threading.png?dl=0\" heigth=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización y niveles de BLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En términos simples vectorizar una operación significa realizar la operación de forma independiente al mismo tiempo sobre diferentes pedazos de datos. La vectorización **sólo puede realizarse** si se llena el caché con los datos usables o relevantes para la operación. Para lograr esto el *bus* moverá pedazos de memoria contiguos lo cual será posible sólo si los datos están almacenados secuencialmente en la memoria. Si se tiene *data fragmentation* causará *memory fragmentation* pues se tendrán los datos esparcidos en la memoria. Aún si se llenara la capacidad del *bus width* si no se tienen los datos usables o relevantes para la operación se tendrán *cache misses*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "En *Python* se tiene *data fragmentation* al usar listas por lo que no se recomienda su uso para realizar operaciones vectoriales o matriciales. Un ejemplo de un paquete que permite realizar operaciones de forma vectorizada es [numpy](https://numpy.org/). Tales operaciones se clasifican de acuerdo a los niveles de BLAS que utilizan.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr la vectorización los paquetes de *software* utilizan el hecho que el cómputo matricial está construído sobre una jerarquía de operaciones del álgebra lineal:\n",
    "\n",
    "* Productos punto involucran operaciones escalares de suma y multiplicación (nivel BLAS 1).\n",
    "\n",
    "* La multiplicación matriz-vector está hecha de productos punto (nivel BLAS 2).\n",
    "\n",
    "* La multiplicación matriz-matriz utiliza colecciones de productos matriz-vector (nivel BLAS 3).\n",
    "\n",
    "Las operaciones anteriores se describen en el álgebra lineal con la teoría de espacios vectoriales pero también es posible describirlas en una forma algorítmica. Ambas descripciones se complementan una a la otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de operación nivel BLAS 1: producto interno estándar o producto punto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideramos $x,y \\in \\mathbb{R}^n$. El producto punto entre $x$ y $y$ es $c = x^Ty = \\displaystyle \\sum_{i=1}^n x_iy_i$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "n=5\n",
    "x=[-1]*n\n",
    "y=[1.5]*n\n",
    "\n",
    "for i in range(n):\n",
    "    c += x[i]*y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementaciones de la API standard de BLAS y LAPACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Ver [Linear Algebra Package: LAPACK](http://www.netlib.org/lapack/explore-html/dir_fa94b7b114d387a7a8beb2e3e22bf78d.html) para nombres que se utilizan para operaciones escalares, vectores o matrices y [Reference-LAPACK / lapack](https://github.com/Reference-LAPACK/lapack) para el repositorio.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Ver [Application Programming Interface: API](https://en.wikipedia.org/wiki/Application_programming_interface) para una explicación de lo que es una API.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En [Handle different versions of BLAS and LAPACK](https://wiki.debian.org/DebianScience/LinearAlgebraLibraries) se explica que [BLAS: Basic Linear Algebra Subprograms](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) y [Linear Algebra Package: LAPACK](http://www.netlib.org/lapack/explore-html/dir_fa94b7b114d387a7a8beb2e3e22bf78d.html) además de ser implementaciones, también son API *standard* para operaciones básicas del álgebra lineal. Muchas implementaciones de la API existen. Un ejemplo de implementaciones son las incluidas al instalar R o Python. Otras son las que se pueden instalar vía línea de comando: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Ver [libblas3](https://packages.debian.org/libblas3) [libblas-dev](https://packages.debian.org/libblas-dev) [liblapack3](https://packages.debian.org/liblapack3) [liblapack-dev](https://packages.debian.org/liblapack-dev).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "sudo apt-get install -y libblas3 libblas-dev liblapack3 liblapack-dev\n",
    "```\n",
    "\n",
    "en un sistema operativo Ubuntu por ejemplo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo existen otras implementaciones de la API que están optimizadas para la arquitectura de nuestras máquinas, por ejemplo:\n",
    "\n",
    "* [OpenBLAS](https://github.com/xianyi/OpenBLAS)\n",
    "\n",
    "* [Atlas](http://math-atlas.sourceforge.net)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es el perfilamiento y por qué es necesario?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{epigraph}\n",
    "\n",
    "Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered\n",
    "\n",
    "--  D. Knuth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{epigraph}\n",
    "\n",
    "We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%\". A good programmer ... will be wise to look carefully at the critical code; but only after that code has been identified\n",
    "\n",
    "--  D. Knuth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El perfilamiento de código nos ayuda a encontrar ***bottlenecks*** de nuestro código ya sea en el uso de CPU, RAM, *network bandwidth* u operaciones hacia el disco de *Input*/*Output* (I/O). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Aún teniendo experiencia en programación identificar algunos *bottlenecks* en los códigos es difícil...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una mala práctica que es común al iniciar en la programación es intentar optimizar el código (y por optimización piénsese en algún caso, por ejemplo mejorar el tiempo de ejecución de un bloque de código) a ciegas, intentando cambiar líneas de código por intuición y no por evidencias o mediciones. Esto aunque puede funcionar en algunas ocasiones no conduce la mayoría de las veces a corregir los problemas de los *bottlenecks* del código (o bien en programas o ¡sistemas enteros!). La optimización guiada por la intuición conduce a un mayor tiempo en el desarrollo para un pequeño incremento en el *performance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien es importante que el código resuelva un problema definido, también es importante perfilarlo. Considérese el caso en el que un código resuelve bien un problema en un día completo, es importante entonces perfilarlo para realizar mediciones (CPU, memoria p.ej.) de los lugares en los que el código gasta la mayor parte de tiempo (en general recursos). \n",
    "\n",
    "A largo plazo el perfilamiento de código te dará las decisiones más pragmáticas posibles con el menor esfuerzo total. \n",
    "\n",
    "Al perfilar tu código no olvides lo siguiente:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "*Overhead* en este caso se refiere a todo lo extra que se añade al perfilar tu código y que no se encuentra en tu código original. Por ejemplo el trabajo extra que realiza tu máquina para analizar tu código (con un paquete por ejemplo) no estaba presente desde un inicio en tu código.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Medir el tiempo total de tus códigos para decidir si se requiere optimizarlos.\n",
    "\n",
    "* Perfilar tus códigos para decidir en dónde se iniciará con la optimización. También ayuda definir hipótesis para decidir en qué bloques perfilar primero.\n",
    "\n",
    "* Escribir *tests* para asegurarse que se resuelve el problema de forma correcta al igual que antes de perfilarlo y optimizarlo.\n",
    "\n",
    "* Cualquier recurso medible puede ser perfilado (no sólo el uso de CPU p.ej.).\n",
    "\n",
    "* Perfilar típicamente añade *overhead* en la ejecución del código (disminución de tiempo de 10x o 100x es común)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También considera el tiempo que inviertes para optimizar tu código y si vale la pena la inversión de tiempo que realizas en esto pues hay códigos que casi no son utilizados y otros que sí. No pierdas de vista:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgs.xkcd.com/comics/is_it_worth_the_time.png\" heigth=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principalmente porque es tentativo caer en la mala práctica de tratar de remover todos los *bottlenecks*. Sé una persona práctica, define un tiempo objetivo para tu código y optimiza sólo para llegar a ese objetivo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas ***strategies to profile your code successfully*** extraídas de [high performance python](https://www.oreilly.com/library/view/high-performance-python/9781492055013/) para un perfilamiento de código exitoso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* *Disable TurboBoost in the BIOS (a cool CPU may run the same block of code faster than a hot CPU)*.\n",
    "\n",
    "* *Disable the operating system's ability to override the SpeedStep (you will find this in your BIOS if you're allowed to control it)*.\n",
    "\n",
    "* *Only use mains power (never battery power) <- a laptop on battery power is likely to more agressively control CPU speed than a laptop on mains power*.\n",
    "\n",
    "* *Disable background tools like backups and Dropbox while running experiments*.\n",
    "\n",
    "* *Run the experiments many times to obtain a stable measurement*.\n",
    "\n",
    "* *Possibly drop to run level 1 (Unix) so that no other tasks are running*.\n",
    "\n",
    "* *Reboot and rerun the experiments to double-confirm the results*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Unit testing*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además del perfilamiento del código, el *unit testing* ayuda a **validar** que cada unidad del *software* trabaje y se desempeñe como fue diseñada (una unidad puede ser una función, programa, procedimiento, método). El *unit testing* es importante pues se debe cuidar que el código genere resultados correctos. Puede realizarse independientemente del perfilamiento y si se ha hecho perfilamiento es muy indispensable que se haga un unit testing.\n",
    "\n",
    "* ***Unit testing during optimization to maintain correctness:*** ... *after spending a day optimizing her code, having disabled unit tests because they were inconvenient, only to discover that her significant speedup result was due to breaking a part of the algorithm she was improving...*\n",
    "\n",
    "* *...If you try to performance test code deep inside a larger project without separating it from the larger project, you are likely to witness side effects that will sidetrack your efforts. It is likely to be harder to unit test a larger project when you're making fine-grained changes, and this may further hamper your efforts. Side effects could include other threads and processes impacting CPU and memory usage and network and disk activity, which will skew your results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Por qué compilar a código de máquina?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Ver [liga](https://en.wikipedia.org/wiki/Interpreter_(computing)) para revisar lo que es un lenguaje tipo intérprete.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las opciones que tenemos a nuestra disposición para resolver *bottlenecks* en nuestro programa es hacer que nuestro código haga menos trabajo. Compilando nuestro código a código de máquina para que el código en los lenguajes tipo intérpretes ejecuten menos instrucciones es una opción a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué puede ser lenta la ejecución de un bloque de código en Python (o en algún otro lenguaje tipo intérprete)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "*Overhead* en este caso se refiere a todo lo extra que debe realizar la máquina en un lenguaje intérprete y que no está presente en un lenguaje compilado. Por ejemplo, un objeto tipo `int` en Python tiene asociado un objeto de alto nivel con el que interactuamos. Tal objeto tiene asociados métodos, funciones y atributos por lo que en el código al querer utilizarlos disminuye eficiencia de ejecución pues deben encontrarse, cargarse, verificar tipo de valores, entre otras operaciones.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Verificación de tipo de valores: si son `int`, `double` o `string` u otros.\n",
    "\n",
    "* Los objetos temporales que se crean por tipo de dato causa *overhead* .\n",
    "\n",
    "* Las llamadas a funciones de alto nivel. Por ejemplo las que ayudan a almacenar al objeto en memoria.\n",
    "\n",
    "son tres de las fuentes que hacen a un lenguaje tipo intérprete como `Python` `R` o `Matlab` lento. También otras fuentes son:\n",
    "\n",
    "* Desde el punto de vista de la memoria de la máquina, el número de referencias a un objeto y las copias entre objetos. \n",
    "\n",
    "* No es posible vectorizar un cálculo sin el uso de extensiones (por ejemplo paquetes como `numpy`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Hay paquetes que permiten la compilación hacia lenguajes más eficientes como Fortran o C (lenguajes que deben realizar compilación), por ejemplo [cython](https://cython.org/) o [rcpp](http://www.rcpp.org/).\n",
    "\n",
    "* Escribir directamente en C en un equipo de desarrollo de *software* indudablemente cambiará la velocidad de su trabajo si no conocen tal lenguaje. \n",
    "\n",
    "* En la práctica si se tiene un *bottleneck* que no ha podido resolverse con herramientas como el cómputo en paralelo o vectorización, se recomienda utilizar paquetes para compilación hacia lenguajes más eficientes en regiones pequeñas del código y así resolver el *bottleneck* del programa.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre los términos concurrencia, paralelo y distribuido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distinción entre los términos de paralelo y distribuido es borrosa y en ocasiones es díficil de distinguir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El término **paralelo** típicamente se relaciona con programas cuya ejecución involucra *cores* o nodos que físicamente son cercanos y comparten memoria o están conectados por una red (*network*). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los programas **distribuidos** son ejecutados por nodos o máquinas separadas a  distancia y una de sus características es que no necesariamente fueron iniciados por un nodo central o *scheduler* por lo que su ejecución es independiente de los demás nodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El término de **concurrencia** se refiere a que las múltiples tareas que debe realizar un programa pueden estar en progreso en cualquier instante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Ver [kernel operating system](https://en.wikipedia.org/wiki/Kernel_(operating_system)) para definición del kernel de una máquina.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo: cada vez que tu código lee un archivo o escribe a un dispositivo, debe pausar su ejecución para contactar al kernel del sistema operativo, solicitar que se ejecute tal operación, y esperar a que se complete (otra operación que requiere contactar al kernel es alojamiento de memoria). Estas operaciones son órdenes de magnitud más lentas que las instrucciones u operaciones ejecutadas en la CPU y el tiempo que el programa espera a que se completen tales operaciones se le nombra *I/O wait*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La concurrencia nos ayuda a utilizar este tiempo perdido al permitir ejecutar operaciones mientras que una operación I/O se complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Ejemplos de paquetes de *Python* para ejecuión del código de forma asíncrona son: [asyncio](https://docs.python.org/3/library/asyncio.html), [tornado](https://www.tornadoweb.org/en/stable/).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un programa concurrente en lugar de ejecutarse de forma secuencial, esto es, pasar de una línea a otra línea, tiene código escrito para ejecutar distintas líneas conforme sucedan \"eventos\". Aquí se involucra una forma de programación llamada **asíncrona**, por ejemplo si una operación tipo I/O es solicitada, el programa ejecuta otras funciones mientras espera que se complete la operación I/O."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Cambiar de función a función en un programa asíncrono también genera costo pues el kernel debe invertir tiempo en hacer todo el *set up* para ejecutar a la función. La concurrencia funciona bien en programas con alto I/O wait.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Por qué el cómputo en paralelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La industria entre los años $2003-2005$ en lugar de fabricar procesadores monolíticos (clásico [Von Neumann](https://en.wikipedia.org/wiki/Von_Neumann_architecture)) que fueran más rápidos y complejos, decidió fabricar múltiples, simples procesadores, *cores*, en un sólo chip para incrementar el poder de procesamiento, disminuir el Von Neumann *bottleneck* y aumentar el *clock speed*.\n",
    "\n",
    "Esto fue motivado pues desde el año $2002$ el incremento del *performance* de los procesadores con un sólo CPU fue de un $20\\%$ por año vs un $50\\%$ por año entre $1986$ y $2002$. Lo anterior se debió a los problemas de la construcción de procesadores monolíticos o de un *core* relacionados con la disipación del calor por un mayor consumo de energía al hacer más pequeños los transistores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoy en día podemos encontrar en nuestros celulares, laptops, computadoras de escritorio y servidores arquitecturas que cuentan con múltiples *cores* o núcleos para procesamiento.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/k11qub01w4nvksi/CPU_multicore.png?dl=0\" heigth=\"500\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchos de los dispositivos anteriores además tienen un(os) procesador(es) gráficos.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/lw9kia12qhwp95r/GPU.png?dl=0\" heigth=\"500\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una buena cantidad de aplicaciones tenemos que implementar algoritmos considerando tal disponibilidad de *cores* para reducir el tiempo de procesamiento. Esto conduce a reimplementar o en otros casos a repensar al algoritmo en sí.\n",
    "\n",
    "\n",
    "Y otro aspecto a tomar en cuenta en esta implementación es la transferencia de datos que existe en la jerarquía de memoria de una máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición \n",
    "\n",
    "Los algoritmos que utilizan un sólo *core* para procesamiento les nombramos **secuenciales**, los que utilizan múltiples *cores* son **paralelos**.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programas cuya ejecución es en paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La decisión de reescribir tu programa secuencial en un programa en paralelo depende mucho de considerar cuatro situaciones:\n",
    "\n",
    "* Tener el hardware para ejecución en paralelo del programa.\n",
    "\n",
    "* Comunicarle al programa que está en un hardware para ejecución en paralelo de instrucciones.\n",
    "\n",
    "* Tener un método que aproveche el hardware paralelo de forma eficiente.\n",
    "\n",
    "* Tiempo invertido en la reescritura de un código secuencial a uno en paralelo vs ganancias en tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es fácilmente alcanzable pues hoy en día tenemos celulares con múltiples *cores* o procesadores. Lo segundo es más dependiente del lenguaje e implementación de éste lenguaje en el que se esté programando. El tercer punto es quizás el más complicado de lograr pues en ocasiones implica repensar el método, disminuir la comunicación lo más posible entre los procesadores, el balanceo de carga o ***load balancing*** debe evaluarse y el perfilamiento o el *debugging* es más difícil en la programación en paralelo que en la forma secuencial. El cuarto punto es esencial para la decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuando es recomendable pensar en ejecutar en paralelo tu programa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tus instrucciones a realizar pueden ser divididas en múltiples *cores* o nodos sin tanto esfuerzo de ingeniería (levantar un clúster de cero es difícil...) o no te lleva mucho tiempo el rediseño de tus métodos para decisiones prácticas (paralelizar el método de despomposición en valores singulares, SVD, es difícil de realizar...) entonces es una opción a considerar. Se recomienda mantener el nivel de paralelización lo más simple posible (aunque no se esté utilizando el 100\\% de todos tus *cores*) de modo que el desarrollo de *software* sea rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si tengo n procesadores ¿espero un *speedup* de $nx$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente **no** se tiene un mejoramiento en la velocidad de $n$ veces ($nx$) (por ejemplo, si tienes una máquina de $8$ *cores* es poco probable que observes un $8x$ *speedup*). \n",
    "\n",
    "Las razones de esto tienen que ver con que al paralelizar instrucciones típicamente se incrementa el *overhead* de la comunicación entre los procesos o *threads* y decrece la memoria RAM disponible que puede ser usada por subprocesos o *threads*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También dentro de las razones se encuentran la [ley de Amdahl](https://en.wikipedia.org/wiki/Amdahl%27s_law) que nos dice que si sólo una parte del código puede ser paralelizado, no importa cuántos cores tengas, en términos totales el código no se ejecutará más rápido en presencia de secciones secuenciales que dominarán el tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿A qué nos referimos al escribir *overhead* en un programa cuya ejecución es en paralelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A todo lo que implica ejecutar el programa en paralelo que no está presente en la ejecución en una forma secuencial. Por ejemplo, iniciar procesos implica comunicación con el kernel del sistema operativo y por tanto, tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cuáles enfoques puedo utilizar para escribir programas en paralelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay $2$ enfoques muy utilizados para escribir programas en paralelo:\n",
    "\n",
    "* Paralelizar las tareas entre los cores. Su característica principal es la ejecución de instrucciones distintas en los cores. Por ejemplo: al llegar la persona invitada a casa, María le ofrecerá de tomar y Luis le abrirá la puerta.\n",
    "\n",
    "* Paralelización de los datos entre los cores. Su característica principal es la ejecución de mismas instrucciones en datos que fueron divididos por alguna metodología previa. Por ejemplo: tú repartes la mitad del pastel a las mesas 1,2 y 3, y yo la otra mitad a las mesas 4,5 y 6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* No son enfoques excluyentes, esto es, podemos encontrar ambos en un mismo programa. La elección de alguno de éstos enfoques depende del problema y del software que será usado para tal enfoque.\n",
    "\n",
    "* Obsérvese que en el ejemplo de María y Luis necesitan **coordinarse**, **comunicarse** y **sincronizarse** para tener éxito en recibir a la invitada.\n",
    "\n",
    "* Obsérvese que en el ejemplo de repartir el pastel se requiere un buen ***load balancing*** pues no queremos que yo le reparta a $5$ mesas y tú le repartas a ¡sólo una!.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿A qué nos referimos con el término *embarrassingly parallel problem*?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A los problemas en los que la comunicación entre procesos o threads es cero. Por ejemplo sumar un array `a` con un array `b`.\n",
    "\n",
    "Y en general si evitamos compartir el estado (pensando a la palabra \"estado\" como un término más general que sólo comunicación) en un sistema paralelo nos hará la vida más fácil (el *speedup* será bueno, el *debugging* será sencillo, el perfilamiento será más fácil de realizar...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo inicio en la programación en paralelo de mi código?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ian Foster en su libro *Designing and Building Parallel Programs* da una serie de pasos que ayudan a la programación en paralelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Partitioning. Divide the computation to be performed and the data operated on by the computation into small tasks. The focus here should be on identifying tasks that can be executed in parallel.*\n",
    "\n",
    "* *Communication. Determine what communication needs to be carried out among the tasks identified in the previous step.*\n",
    "\n",
    "* *Agglomeration or aggregation. Combine tasks and communications identified in the first step into larger tasks. For example, if task A must be executed before task B can be executed, it may make sense to aggregate them into a single composite task.*\n",
    "\n",
    "* *Mapping. Assign the composite tasks identified in the previous step to processes/threads. This should be done so that communication is minimized, and each process/thread gets roughly the same amount of work.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "En ocasiones es mejor dejar las tareas simples y redundantes que complicarlas y no redundantes. Por ejemplo, si en el programa en paralelo varios procesadores o *threads* hacen tarea redundante pero me evitan la comunicación, prefiero este programa a uno en el que haga  trabajo no redundate y muy específico a cada procesador o *thread* pero que la comunicación a realizar sea muy complicada o compleja.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo en la regla del rectángulo compuesta en una máquina *multicore* para CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *Partitioning*: la tarea a realizar es el cálculo de un área de un rectángulo para un subintervalo.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/5nqciu6ca5xzdh9/parallel_processing_Rcf_1.png?dl=0\" heigth=\"300\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. *Communication* y *mapping*: los subintervalos deben repartirse entre los *cores* y se debe comunicar esta repartición por algún medio (por ejemplo con variables en memoria).\n",
    "\n",
    "3. *Aggregation*: un *core* puede calcular más de un área de un rectángulo si recibe más de un subintervalo. \n",
    "\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/lpcwd9mejb90rq3/parallel_processing_Rcf_2.png?dl=0\" heigth=\"200\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. *Communication* y *mapping*: el área de los rectángulos calculados por cada procesador deben sumarse para calcular la aproximación a la integral.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/mfo5rfzjnonn8lq/parallel_processing_Rcf_3.png?dl=0\" heigth=\"400\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Software?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depende si lo que deseamos usar son *cores* en una CPU tenemos:\n",
    "\n",
    "* [Dask](https://docs.dask.org/en/latest/), [multiprocessing](https://docs.python.org/3.1/library/multiprocessing.html), [parallel](https://www.rdocumentation.org/packages/parallel/versions/3.6.2),  [openMP](http://www.openmp.org/), [Thrust](https://thrust.github.io/) ...\n",
    "\n",
    "Si deseamos usar *cores* en una GPU tenemos:\n",
    "\n",
    "* [CUDA C](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html), [CuPy](https://docs.cupy.dev/en/stable/), [PyCUDA](https://documen.tician.de/pycuda/), [gputools](https://www.rdocumentation.org/packages/gputools/versions/1.1), [Thrust](https://thrust.github.io/) ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Ejercicios\n",
    ":class: tip\n",
    "\n",
    "1.Resuelve los ejercicios y preguntas de la nota.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas de comprehensión:**\n",
    "\n",
    "1)¿Qué factores han influido en que desde el 2002-2003 a la fecha, el *performance* de los procesadores se esté incrementando en un 20% por año vs el 50% de incremento por año que se tenía entre 1986 y 2002?\n",
    "\n",
    "2)Menciona los componentes y realiza un esquema de una arquitectura von Neumann y descríbelas.\n",
    "\n",
    "3)Menciona la ley de Amdahl.\n",
    "\n",
    "4)¿Qué es un proceso y de qué consta?\n",
    "\n",
    "5)¿Qué es un *thread*?\n",
    "\n",
    "6)¿Qué es el *threading*? ¿qué ventajas nos da para la programación en un sistema de memoria compartida?\n",
    "\n",
    "7)¿Qué es el caché?\n",
    "\n",
    "8)Nosotros como programadores o programadoras, ¿cómo podemos obtener ventajas del caché?\n",
    "\n",
    "9)¿Qué es un *cache hit*? ¿un *cache miss*?\n",
    "\n",
    "10)De acuerdo a la taxonomía de Flynn, ¿qué tipos de arquitecturas existen? Menciona sus características, ventajas /desventajas y ejemplos.\n",
    "\n",
    "11)Menciona algunos ejemplos de:\n",
    "\n",
    "a.Sistemas de memoria distribuida.\n",
    "b.Sistemas de memoria compartida.\n",
    "    \n",
    "12)¿Qué es el *pipelining* y el *branch prediction*?\n",
    "\n",
    "13)Menciona los distintos *bus* o interconexiones en un sistema de computadora y su propiedad principal o lo que nos interesa medir en un *bus*.\n",
    "\n",
    "14)¿Qué significan los términos concurrencia, paralelo, distribuido?\n",
    "\n",
    "15)¿Cuáles son los enfoques que se utilizan para escribir programas en paralelo?\n",
    "\n",
    "16)Define a cuál enfoque corresponde (de acuerdo a la pregunta 13) cada uno de los siguientes incisos:\n",
    "\n",
    "a)Supón que tienes 2 cores y un arreglo de tamaño 100\n",
    "\n",
    "if(rango_core módulo 2 == 0 )\n",
    "    operar en los elementos 50 a 99\n",
    "else\n",
    "    operar en los elementos 0 a 49\n",
    "    \n",
    "Donde módulo es una operación que nos devuelve el residuo al dividir un número entre otro.\n",
    "    \n",
    "b)Tenemos tres trabajadores: Aurora, Pedro, Daniel\n",
    "    \n",
    "if(mi_nombre es Pedro)\n",
    "    lavo el baño\n",
    "else\n",
    "    voy de compras\n",
    "            \n",
    "17)En el cómputo en paralelo debemos realizar coordinación entre procesos o *threads* y considerar el *load balancing*. Menciona tipos de coordinación que existen y ¿a qué se refiere el *load balancing*?\n",
    "\n",
    "18)¿Cuáles son los pasos a seguir, que de acuerdo a Ian Foster, se puede seguir para el diseño de programas en paralelo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "1. M. Gorelick, I. Ozsvald, High Performance Python, O'Reilly Media, 2014.\n",
    "\n",
    "2. E. Anderson, Z. Bai, C. Bischof, L. S. Blackford, J. Demmel, J. Dongarra, J. Du Croz,\n",
    "A. Greenbaum, S. Hammarling, A. Mckenney and D. Sorensen, LAPACK Users Guide, Society for Industrial and Applied Mathematics, Philadelphia, PA, third ed., 1999.\n",
    "\n",
    "3. P. Pacheco, An Introduction to Parallel Programming, Morgan Kaufmann, 2011.\n",
    "\n",
    "4. https://xkcd.com/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
