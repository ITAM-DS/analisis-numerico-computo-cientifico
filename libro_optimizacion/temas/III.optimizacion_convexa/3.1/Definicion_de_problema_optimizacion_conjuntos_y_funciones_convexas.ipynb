{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(DPOCFC)="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Definición de problemas de optimización, conjuntos y funciones convexas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Notas para contenedor de docker:\n",
    "\n",
    "Comando de docker para ejecución de la nota de forma local:\n",
    "\n",
    "nota: cambiar `<ruta a mi directorio>` por la ruta de directorio que se desea mapear a `/datos` dentro del contenedor de docker.\n",
    "\n",
    "`docker run --rm -v <ruta a mi directorio>:/datos --name jupyterlab_optimizacion -p 8888:8888 -d palmoreck/jupyterlab_optimizacion:2.1.4`\n",
    "\n",
    "password para jupyterlab: `qwerty`\n",
    "\n",
    "Detener el contenedor de docker:\n",
    "\n",
    "`docker stop jupyterlab_optimizacion`\n",
    "\n",
    "Documentación de la imagen de docker `palmoreck/jupyterlab_optimizacion:2.1.4` en [liga](https://github.com/palmoreck/dockerfiles/tree/master/jupyterlab/optimizacion).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota generada a partir de [liga1](https://www.dropbox.com/s/qb3swgkpaps7yba/4.1.Introduccion_optimizacion_convexa.pdf?dl=0), [liga2](https://www.dropbox.com/s/6isby5h1e5f2yzs/4.2.Problemas_de_optimizacion_convexa.pdf?dl=0), [liga3](https://www.dropbox.com/s/ko86cce1olbtsbk/4.3.1.Teoria_de_convexidad_Conjuntos_convexos.pdf?dl=0), [liga4](https://www.dropbox.com/s/mmd1uzvwhdwsyiu/4.3.2.Teoria_de_convexidad_Funciones_convexas.pdf?dl=0), [liga5](https://drive.google.com/file/d/1xtkxPCx05Xg4Dj7JZoQ-LusBDrtYUqOF/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Al final de esta nota el y la lectora:\n",
    ":class: tip\n",
    "\n",
    "* \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Problemas de optimización numérica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una gran cantidad de aplicaciones plantean problemas de optimización. Tenemos problemas básicos que se presentan en cursos iniciales de cálculo:\n",
    "\n",
    "*Una caja con base y tapa cuadradas debe tener un volumen de $100 cm^3$. Encuentre las dimensiones de la caja que minimicen la cantidad de material.*\n",
    "\n",
    "Y tenemos más especializados que encontramos en áreas como estadística, ingeniería, finanzas o *machine learning*:\n",
    "\n",
    "* Ajustar un modelo de regresión lineal a un conjunto de datos.\n",
    "\n",
    "* Buscar la mejor forma de invertir un capital en un conjunto de activos.\n",
    "\n",
    "* Elección del ancho y largo de un dispositivo en un circuito electrónico.\n",
    "\n",
    "* Ajustar un modelo que clasifique un conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general un problema de optimización matemática o numérica tiene la forma:\n",
    "\n",
    "$$\\displaystyle \\min f_o(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{sujeto a:} f_i(x) \\leq b_i, i=1,\\dots, m$$\n",
    "\n",
    "donde: $x=(x_1,x_2,\\dots, x_n)^T$ es la **variable de optimización del problema**, la función $f_o: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ es la **función objetivo**, las funciones $f_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}, i=1,\\dots,m$ son las **funciones de restricción** (aquí se colocan únicamente desigualdades pero pueden ser sólo igualdades o bien una combinación de ellas) y las constantes $b_1,b_2,\\dots, b_m$ son los **límites o cotas de las restricciones**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un vector $x^* \\in \\mathbb{R}^n$ es nombrado **óptimo** o solución del problema anterior si tiene el valor más pequeño de entre todos los vectores $x \\in \\mathbb{R}^n$ que satisfacen las restricciones. Por ejemplo, si $z \\in \\mathbb{R}^n$ satisface $f_1(z) \\leq b_1, f_2(z) \\leq b_2, \\dots, f_m(z) \\leq b_m$ y $x^*$ es óptimo entonces $f_o(z) \\geq f_o(x^*)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Se consideran funciones objetivo $f_o: \\mathbb{R}^n \\rightarrow \\mathbb{R}$, sin embargo, hay formulaciones que utilizan $f_o: \\mathbb{R}^n \\rightarrow \\mathbb{R}^q$. Tales formulaciones pueden hallarlas en la optimización multicriterio, multiobjetivo, vectorial o también nombrada Pareto, ver [Multi objective optimization](https://en.wikipedia.org/wiki/Multi-objective_optimization).\n",
    "\n",
    "* El problema de optimización definido utiliza una forma de minimización y no de maximización. Típicamente en la literatura por convención se consideran problemas de este tipo. Además minimizar $f_o$ y maximizar $-f_o$ son **problemas de optimización equivalentes**: a grandes rasgos dos problemas de optimización son equivalentes si con la solución de uno de ellos se obtiene la solución del otro y viceversa.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\displaystyle \\min_{x \\in \\mathbb{R}^n} ||x||_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{sujeto a:} Ax \\leq b$$\n",
    "\n",
    "\n",
    "con $A \\in \\mathbb{R}^{m \\times n}, b \\in \\mathbb{R}^m$. En este problema buscamos el vector $x$ que es solución del problema $Ax \\leq b$ con **mínima norma Euclidiana**. La función objetivo es $f_o(x)=||x||_2$, las funciones de restricción son las desigualdades lineales $f_i(x) = a_i^Tx \\leq b_i$ con $a_i$ $i$-ésimo renglón de $A$ y $b_i$ $i$-ésima componente de $b$, $\\forall i=1,\\dots,m$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Un problema similar al anterior lo podemos encontrar en resolver el sistema de ecuaciones lineales $Ax=b$ *underdetermined* en el que $m < n$ y se busca el vector $x$ con mínima norma Euclidiana que satisfaga tal sistema. Tal sistema puede tener infinitas soluciones o ninguna solución.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encuentra el punto en la gráfica de $y=x^2$ que es más cercano al punto $P=(1,0)$ bajo la norma Euclidiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deseamos minimizar la cantidad $||(1,0)-(x,y)||_2$. Además $y = y(x)$ por lo que reescribiendo lo anterior se tiene $f_o(x) = ||(1,0)-(x,x^2)||_2=||(1-x,-x^2)||_2=\\sqrt{(1-x)^2+x^4}$. Entonces el problema de optimización (sin restricciones) es:\n",
    "\n",
    "$$\\displaystyle \\min_{x \\in \\text{dom}f_o}\\sqrt{(1-x)^2+x^4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Optimización numérica convexa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicaciones de *machine learning* conducen al planteamiento de problemas de optimización convexa y no convexa. Por ejemplo en la aplicación de clasificación de textos, en donde se desea asignar un texto a clases definidas de acuerdo a su contenido (determinar si un documento de texto es sobre un tema), puede formularse un problema convexo a partir de una **función de pérdida convexa**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{sidebar} Un poco de historia...\n",
    "\n",
    "Los tipos de redes neuronales profundas, *deep neural networks*, que han sido mayormente usadas en el inicio del siglo XXI son las mismas que las que eran populares en los años $90$'s. El éxito de éstos tipos y su uso primordialmente se debe a la disponibilidad de *larger datasets* y mayores recursos computacionales.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplos de aplicaciones en la **optimización no convexa** están el reconocimiento de voz y reconocimiento de imágenes. El uso de [redes neuronales](https://en.wikipedia.org/wiki/Artificial_neural_network) [profundas](https://en.wikipedia.org/wiki/Deep_learning) ha tenido muy buen desempeño en tales aplicaciones haciendo uso de cómputo en la GPU, ver [2.3.CUDA](https://github.com/ITAM-DS/analisis-numerico-computo-cientifico/blob/master/temas/II.computo_paralelo/2.3.CUDA.ipynb), [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), [2012: A Breakthrough Year for Deep Learning](https://medium.com/limitlessai/2012-a-breakthrough-year-for-deep-learning-2a31a6796e73). En este caso se utilizan **funciones objetivo no lineales y no convexas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Desde los $40$'s se han desarrollado algoritmos para resolver problemas de optimización, se han analizado sus propiedades y se han desarrollado buenas implementaciones de software.  Sin embargo, una clase de problemas de optimización en los que encontramos métodos **efectivos** son los convexos. \n",
    "\n",
    "* Métodos para optimización no convexa utilizan parte de la teoría de convexidad desarrollada en optimización convexa. Además un buen número de problemas de aprendizaje utilizan funciones de pérdida convexas.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(PESTOPT)="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema estándar de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que continúa se considera $f_0 = f_o$ (el subíndice \"0\" y el subíndice \"o\" son iguales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Un problema estándar de optimización es:\n",
    "\n",
    "$$\\displaystyle \\min f_o(x)$$\n",
    "\n",
    "$$\\text{sujeto a:}$$\n",
    "\n",
    "$$f_i(x) \\leq 0, \\quad \\forall i=1,\\dots,m$$\n",
    "\n",
    "$$h_i(x) = 0, \\quad \\forall i=1,\\dots,p$$\n",
    "\n",
    "con $f_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ $\\forall i=0,\\dots,m$, $h_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}$, $\\forall i=1,\\dots,p$. $f_i$ son las **restricciones de desigualdad**, $h_i$ son las **restricciones de igualdad**.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominio del problema de optimización y puntos factibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definiciones\n",
    "\n",
    "* El conjunto de puntos para los que la función objetivo y las funciones de restricción $f_i, h_i$ están definidas se nombra **dominio del problema de optimización**, esto es:\n",
    "\n",
    "$$\\mathcal{D} = \\bigcap_{i=0}^m\\text{dom}f_i \\cap \\bigcap_{i=1}^p\\text{dom}h_i.$$\n",
    "\n",
    "\n",
    "* Un punto $x \\in \\mathcal{D}$ se nombra **factible** si satisface las restricciones de igualdad y desigualdad. El conjunto de puntos factibles se nombra **conjunto de factibilidad**.\n",
    "\n",
    "* El {ref}`problema estándar de optimización <PESTOPT>` se nombra **problema de optimización factible** si existe **al menos un punto factible**, si no se cumple lo anterior entonces es infactible.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valor óptimo del problema de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Se asumen todos los puntos en el dominio del problema de optimización $\\mathcal{D}$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "El valor óptimo del problema se denota como $p^*$. En notación matemática es:\n",
    "\n",
    "$$p^* = \\inf\\{f_o(x) | f_i(x) \\leq 0, \\forall i=1,\\dots,m, h_i(x) = 0 \\forall i=1,\\dots,p\\}$$\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Si el problema es **infactible** entonces $p^* = \\infty$.\n",
    "\n",
    "* Si $\\exists x_k$ factible tal que $f_o(x_k) \\rightarrow -\\infty$ para $k \\rightarrow \\infty$ entonces $p^*=-\\infty$ y se nombra **problema de optimización no acotado por debajo**.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto óptimo del problema de optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Se asumen todos los puntos en el dominio del problema de optimización $\\mathcal{D}$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "$x^*$ es **punto óptimo** si es factible y $f_o(x^*) = p^*$. \n",
    "\n",
    "El conjunto de óptimos se nombra **conjunto óptimo** y se denota:\n",
    "\n",
    "$$X_{\\text{opt}} = \\{x | f_i(x) \\leq 0 \\forall i=1,\\dots,m, h_i(x) =0 \\forall i=1,\\dots,p, f_o(x) = p^*\\}$$\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* La propiedad de un punto óptimo $x^*$ es que si $z$ satisface las restricciones $f_i(z) \\leq 0$ $\\forall i=1,...,m$, $h_i(z)=0$ $\\forall i=1,..,p$ se tiene: $f(x^*) \\leq f(z)$. Es **óptimo estricto** si $z$ satisface las restricciones y $f_o(x^*) < f_o(z)$.\n",
    "\n",
    "* Si existe un punto óptimo se dice que el **valor óptimo se alcanza** y por tanto el problema de optimización tiene solución, es ***solvable***.\n",
    "\n",
    "* Si $X_{\\text{opt}} = \\emptyset$ se dice que el valor óptimo no se alcanza. Obsérvese que para problemas no acotados nunca se alcanza el valor óptimo.\n",
    "\n",
    "* Si $x$ es factible y $f_o(x) \\leq p^* + \\epsilon$ con $\\epsilon >0$, $x$ se nombra **$\\epsilon$-subóptimo** y el conjunto de puntos $\\epsilon$-subóptimos se nombra **conjunto $\\epsilon$-subóptimo**.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Óptimo local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Se asumen todos los puntos en el dominio del problema de optimización $\\mathcal{D}$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Un punto factible $x^*$ se nombra **óptimo local** si $\\exists R > 0$ tal que:\n",
    "\n",
    "$$f_o(x^*) = \\inf \\{f_o(z) | f_i(z) \\leq 0 \\forall i=1,\\dots,m, h_i(z) = 0 \\forall i=1,\\dots, p, ||z-x||_2 \\leq R\\}.$$\n",
    "\n",
    "Así, $x^*$ resuelve:\n",
    "\n",
    "$$\\displaystyle \\min f_o(z)$$\n",
    "\n",
    "$$\\text{sujeto a:}$$\n",
    "\n",
    "$$f_i(z) \\leq 0, \\forall i =1,\\dots,m$$\n",
    "\n",
    "$$h_i(z) =0, \\forall i=1,\\dots,p$$\n",
    "\n",
    "$$||z-x||_2 \\leq R$$\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "La palabra **óptimo** se utiliza para **óptimo global**, esto es, no consideramos la última restricción $||z-x||_2 \\leq R$ en el problema de optimización y exploramos en todo el $\\text{dom}f$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/xyprhh7erbb6icb/min-max-points-example.png?dl=0\" heigth=\"700\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricciones activas, no activas y redundantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Se asumen todos los puntos en el dominio del problema de optimización $\\mathcal{D}$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Si $x$ es factible y $f_i(x)=0$ entonces la restricción de desigualdad $f_i(x) \\leq 0$ se nombra **restricción activa en $x$**. Se nombra **inactiva en $x$** si $f_i(x) <0$ para alguna $i$.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* Las restricciones de igualdad, $h_i(x)$, siempre son activas en el conjunto factible. \n",
    "\n",
    "* Una restricción se nombra **restricción redundante** si al quitarla el conjunto factible no se modifica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas de optimización convexa en su forma estándar o canónica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Se asumen todos los puntos en el dominio del problema de optimización $\\mathcal{D}$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Recuerda que una función afín es de la forma $h(x) = Ax+b$ con $A \\in \\mathbb{R}^{p \\times n}$ y $b \\in \\mathbb{R}^p$. En la definición $h_i(x) = a_i^Tx-b_i$ con $a_i \\in \\mathbb{R}^n$, $b_i \\in \\mathbb{R}$ $\\forall i=1,\\dots,p$ y geométricamente $h_i(x)$ es un **hiperplano** en $\\mathbb{R}^n$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Se define un problema de optimización convexa en su forma estándar o canónica como:\n",
    "\n",
    "$$\\displaystyle \\min f_o(x)$$\n",
    "\n",
    "$$\\text{sujeto a:}$$\n",
    "\n",
    "$$f_i(x) \\leq 0 , i=1,\\dots,m$$\n",
    "\n",
    "$$h_i(x)=0, i=1,\\dots,p$$\n",
    "\n",
    "donde: $f_i$ son **convexas** $\\forall i=0,2,\\dots,m$ y $h_i$ **es afín** $\\forall i =1,\\dots,p$. \n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Un conjunto $\\alpha$-subnivel es de la forma $\\{x \\in \\text{dom}f | f(x) \\leq \\alpha\\}$. Un conjunto subnivel contiene las curvas de nivel de $f$, ver [Level set](https://en.wikipedia.org/wiki/Level_set):\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/0woqoj8foo5eco9/level_set_of_func.png?dl=0\" heigth=\"300\" width=\"300\">\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* El conjunto de factibilidad de un problema de optimización convexa es un conjunto convexo. Esto se sigue pues es una intersección finita de conjuntos convexos: intersección entre las $x$'s que satisfacen $f_i(x) \\leq 0$, que se nombra **conjunto subnivel**, y las $x$'s que están en un hiperplano.\n",
    "\n",
    "\n",
    "* Si en el problema anterior se tiene que **maximizar** una $f_o$ función objetivo **cóncava** y se tienen misma forma estándar: $f_i$ convexa, $h_i$ afín entonces también se nombra al problema como **problema de optimización convexa**. Todos los resultados, conclusiones y algoritmos desarrollados para los problemas de minimización son aplicables para maximización. En este caso se puede resolver un problema de maximización al minimizar la función objetivo  $-f_o$ que es convexa.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función convexa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Sea $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ una función con el conjunto $\\text{dom}f$ convexo. $f$ se nombra convexa  (en su $\\text{dom}f$) si $\\forall x,y \\in \\text{dom}f$ y $\\theta \\in [0,1]$ se cumple:\n",
    "\n",
    "$$f(\\theta x + (1-\\theta) y) \\leq \\theta f(x) + (1-\\theta)f(y).$$\n",
    "\n",
    "Si la desigualdad se cumple de forma estricta $\\forall x \\neq y$ $f$ se nombra **estrictamente convexa**.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observaciones\n",
    ":class: tip\n",
    "\n",
    "* La convexidad de $f$ se define para $\\text{dom}f$ aunque para casos en particular se detalla el conjunto en el que $f$ es convexa.\n",
    "\n",
    "* La desigualdad que define a funciones convexas se nombra [**desigualdad de Jensen**](https://en.wikipedia.org/wiki/Jensen%27s_inequality).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propiedades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las propiedades que tiene una función convexa se encuentran las siguientes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Si $f$ es convexa el conjunto subnivel es un conjunto convexo. \n",
    "\n",
    "* $\\text{dom}f$ es convexo $\\therefore$ $\\theta x + (1-\\theta)y \\in \\text{dom}f$\n",
    "\n",
    "\n",
    "* $f$ es **cóncava** si $-f$ es convexa y **estrictamente cóncava** si $-f$ es estrictamente convexa. Otra forma de definir concavidad es con una desigualdad del tipo:\n",
    "\n",
    "$$f(\\theta x + (1-\\theta) y) \\geq \\theta f(x) + (1-\\theta)f(y).$$\n",
    "\n",
    "y mismas definiciones para $x,y, \\theta$ que en la definición de convexidad.\n",
    "\n",
    "* Si $f$ es convexa, geométricamente el segmento de línea que se forma con los puntos $(x,f(x)), (y,f(y))$ está por encima o es igual a $f(\\theta x + (1-\\theta)y) \\forall \\theta \\in [0,1]$ y $\\forall x,y \\in \\text{dom}f$:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/fdcx1k150nfwykv/draw_convexity_for_functions.png?dl=0\" heigth=\"300\" width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjuntos convexos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Línea y segmentos de línea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Sean $x_1, x_2 \\in \\mathbb{R}^n$ con $x_1 \\neq x_2$. Entonces el punto:\n",
    "\n",
    "$$y = \\theta x_1 + (1-\\theta)x_2$$\n",
    "\n",
    "con $\\theta \\in \\mathbb{R}$ se encuentra en la línea que pasa por $x_1$ y $x_2$. $\\theta$ se le nombra parámetro y si $\\theta \\in [0,1]$ tenemos un segmento de línea:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/dldljf5igy8xt9d/segmento_linea.png?dl=0\" heigth=\"200\" width=\"200\">\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "* $y = \\theta x_1 + (1-\\theta)x_2 = x_2 + \\theta(x_1 -x_2)$ y esta última igualdad se interpreta como \"$y$ es la suma del punto base $x_2$ y la dirección $x_1-x_2$ escalada por $\\theta$\". \n",
    "\n",
    "* Si $\\theta=0$ entonces $y=x_2$. Si $\\theta \\in [0,1]$ entonces $y$ se \"mueve\" en la dirección $x_1-x_2$ hacia $x_1$ y si $\\theta>1$ entonces $y$ se encuentra en la línea \"más allá\" de $x_1$:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/nbahrio7p1mj4hs/segmento_linea_2.png?dl=0\" heigth=\"350\" width=\"350\">\n",
    "\n",
    "\n",
    "El punto entre $x_1$ y $x_2$ tiene $\\theta=\\frac{1}{2}$.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto convexo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Un conjunto $\\mathcal{C}$ es convexo si el segmento de línea entre cualquier par de puntos de $\\mathcal{C}$ está completamente contenida en $\\mathcal{C}$. Esto se escribe matemáticamente como:\n",
    "\n",
    "$$\\theta x_1 + (1-\\theta) x_2 \\in \\mathcal{C} \\quad \\forall \\theta \\in [0,1], \\forall x_1, x_2 \\in \\mathcal{C}.$$\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos gráficos de conjuntos convexos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/gj54ism1lqojot6/ej_conj_convexos.png?dl=0\" heigth=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplos gráficos de conjuntos no convexos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://dl.dropboxusercontent.com/s/k37zh5v3iq3kx04/ej_conj_no_convexos.png?dl=0\" heigth=\"350\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "\n",
    "* El punto $\\displaystyle \\sum_{i=1}^k \\theta_i x_i$ con $\\displaystyle \\sum_{i=1}^k \\theta_i=1$, $\\theta_i \\geq 0 \\forall i=1,\\dots,k$ se nombra **combinación convexa** de los puntos $x_1, x_2, \\dots, x_k$. Una combinación convexa de los puntos $x_1, \\dots, x_k$ puede pensarse como una mezcla o promedio ponderado de los puntos, con $\\theta_i$ la fracción $\\theta_i$ de $x_i$ en la mezcla.\n",
    "\n",
    "* Un conjunto es convexo si y sólo si contiene cualquier combinación convexa de sus puntos.\n",
    "\n",
    "* El conjunto óptimo y los conjuntos $\\epsilon$-subóptimos son convexos.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de funciones convexas y cóncavas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una función afín es convexa y cóncava en todo su dominio: $f(x) = Ax+b$ con $A \\in \\mathbb{R}^{m \\times n}, b \\in \\mathbb{R}^n$, $\\text{dom}f = \\mathbb{R}^n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Observación\n",
    ":class: tip\n",
    "\n",
    "Por tanto las funciones lineales también son convexas y cóncavas.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Funciones cuadráticas: $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$, $f(x) = \\frac{1}{2} x^TPx + q^Tx + r$ son convexas en su dominio: $\\mathbb{R}^n$. $P \\in \\mathcal{S}_+^n, q \\in \\mathbb{R}^n, r \\in \\mathbb{R}$ con $\\mathbb{S}_+^n$ conjunto de **matrices simétricas positivas semidefinidas**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Una matriz $A$ es positiva semidefinida si $x^TAx \\geq 0$ $\\forall x \\in \\mathbb{R}^n - \\{0\\}$. Si se cumple de forma estricta la desigualdad entonces $A$ es **positiva definida**. Con los eigenvalores podemos caracterizar a las matrices definidas y semidefinidas positivas: $A$ es semidefinida positiva si y sólo si los eigenvalores de $T=\\frac{A+A^T}{2}$ son no negativos. Es definida positiva si y sólo si los eigenvalores de $T$ son positivos. Los conjuntos de matrices que se utilizan para definir a matrices semidefinidas positivas y definidas positivas son $\\mathbb{S}_{+}^n$ y $\\mathbb{S}_{++}^n$ respectivamente ($\\mathbb{S}$ es el conjunto de matrices simétricas).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "$f$ es estrictamente convexa si y sólo si $P \\in \\mathbb{S}_{++}^n$. $f$ es cóncava si y sólo si $P \\in -\\mathbb{S}_+^n$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exponenciales: $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, $f(x) = e^{ax}$ para cualquier $a \\in \\mathbb{R}$ es convexa en su dominio: $\\mathbb{R}$.\n",
    "\n",
    "* Potencias: $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, $f(x)=x^a$:\n",
    "\n",
    "    * Si $a \\geq 1$ o $a \\leq 0$ entonces $f$ es convexa en $\\mathbb{R}_{++}$ (números reales positivos).\n",
    "    * Si $0 \\leq a \\leq 1$ entonces $f$ es cóncava en $\\mathbb{R}_{++}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Potencias del valor absoluto: $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, $f(x)=|x|^p$ con $p \\geq 1$ es convexa en $\\mathbb{R}$.\n",
    "\n",
    "* Logaritmo: $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, $f(x) = \\log(x)$ es cóncava en su dominio: $\\mathbb{R}_{++}$.\n",
    "\n",
    "* Entropía negativa: $f(x) = \\begin{cases}\n",
    "x\\log(x) &\\text{ si } x > 0 ,\\\\\n",
    "0 &\\text{ si } x = 0\n",
    "\\end{cases}$ es estrictamente convexa en su dominio: $\\mathbb{R}_+$.\n",
    "\n",
    "* Normas: cualquier norma es convexa en su dominio.\n",
    "\n",
    "* Función máximo: $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$, $f(x) = \\max\\{x_1,\\dots,x_n\\}$ es convexa.\n",
    "\n",
    "* Función log-sum-exp: $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$, $f(x)=\\log\\left(\\displaystyle \\sum_{i=1}^ne^{x_i}\\right)$ es convexa en su dominio: $\\mathbb{R}^n$.\n",
    "\n",
    "* La media geométrica: $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$, $f(x) = \\left(\\displaystyle \\prod_{i=1}^n x_i \\right)^\\frac{1}{n}$ es cóncava en su dominio: $\\mathbb{R}_{++}^n$.\n",
    "\n",
    "* Función log-determinante: $f: \\mathbb{S}^{n} \\rightarrow \\mathbb{R}^n$, $f(x) = \\log(\\det(X))$ es cóncava en su dominio: $\\mathbb{S}_{++}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados útiles de teoría de convexidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "\n",
    "Se sugiere revisar {ref}`definición de función, continuidad y derivada <FCD>` y {ref}`condición de un problema y estabilidad de un algoritmo <CPEA>` como recordatorio de definiciones. En particular las **definiciones de primera y segunda derivada, gradiente y Hessiana** para la primer nota y la **definición de número de condición de una matriz** para la segunda.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre funciones convexas/cóncavas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Sea $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ diferenciable entonces $f$ es convexa si y sólo si $\\text{dom}f$ es un conjunto convexo y se cumple:\n",
    "\n",
    "$$f(y) \\geq f(x) + \\nabla f(x)^T(y-x) \\forall x,y \\in \\text{dom}f.$$\n",
    "\n",
    "Si se cumple de forma estricta la desigualdad $f$ se nombra estrictamente convexa. También si su $\\text{dom}f$ es convexo y se tiene la desigualdad en la otra dirección \"$\\leq$\" entonces $f$ es cóncava.\n",
    "\n",
    "Geométricamente este resultado se ve como sigue para $\\nabla f(x) \\neq 0$:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/e581e22xeejdwu0/convexidad_con_hiperplano_de_soporte.png?dl=0\" heigth=\"350\" width=\"350\">\n",
    "\n",
    "\n",
    "y el hiperplano $f(x) + \\nabla f(x)^T(y-x)$ se nombra **hiperplano de soporte para la función $f$ en el punto $(x,f(x))$**. Obsérvese que si $\\nabla f(x)=0$ se tiene $f(y) \\geq f(x) \\forall y \\in \\text{dom}f$ y por lo tanto $x$ es un mínimo global de $f$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una función es convexa si y sólo si es convexa al restringirla a cualquier línea que intersecte su dominio, esto es, si $g(t) = f(x + tv)$ es convexa $\\forall x,v \\in \\mathbb{R}^n$, $\\forall t \\in \\mathbb{R}$ talque $x + tv \\in \\text{dom}f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sea $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ tal que $f \\in \\mathcal{C}^2(\\text{dom}f)$. Entonces $f$ es convexa en $\\text{dom}f$ si y sólo si $\\text{dom}f$ es convexo y $\\nabla^2f(x) \\in \\mathbb{S}^n_+$ en $\\text{dom}f$. Si $\\nabla^2f(x) \\in \\mathbb{S}^n_{++}$ en $\\text{dom}f$ y $\\text{dom}f$ es convexo entonces $f$ es estrictamente convexa en $\\text{dom}f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Para una función: $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, la hipótesis del enunciado anterior ($\\nabla^2 f(x) \\in \\mathbb{S}^n_{++}$ en $\\text{dom}f$) es que la segunda derivada sea positiva. El recíproco no es verdadero, para ver esto considérese $f(x)=x^4$ la cual es estrictamente convexa en $\\text{dom}f$ pero su segunda derivada en $0$ no es positiva.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre problemas de optimización\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Si $f$ es diferenciable y $x^*$ es óptimo entonces $\\nabla f(x^*) = 0$.\n",
    "\n",
    "* Si $f \\in \\mathcal{C}^2(\\text{domf})$ y $x^*$ es mínimo local entonces $\\nabla^2 f(x^*)$ es una matriz simétrica semidefinida positiva.\n",
    "\n",
    "* Si $f \\in \\mathcal{C}^2(\\text{domf})$, $\\nabla f(x^*)=0$ y $\\nabla^2f(x^*)$ es una matriz simétrica definida positiva entonces $x^*$ es mínimo local estricto.\n",
    "\n",
    "* Una propiedad fundamental de un óptimo local en un problema de optimización convexa es que también es un óptimo global.\n",
    "\n",
    "* Si $f_o$ en un problema de optimización convexa es diferenciable y $X$ es el conjunto de factibilidad entonces $x$ es óptimo si y sólo si $x \\in X$ y $\\nabla f_o(x)^T(y-x) \\geq 0$ $\\forall y \\in X$. Si en lo anterior se considera como conjunto de factibilidad $X = \\text{dom}f_o$ (que es un problema sin restricciones) la propiedad se reduce a la condición: $x$ es óptimo si y sólo si $\\nabla f_o(x) = 0$.\n",
    "\n",
    "Geométricamente el resultado anterior se visualiza para $\\nabla f(x) \\neq 0$ y $-\\nabla f(x)$ apuntando hacia la dirección dibujada:\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/0tmpivvo5ob4oox/optimo_convexidad_con_hiperplano_de_soporte.png?dl=0\" heigth=\"550\" width=\"550\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentario\n",
    "\n",
    "Por los resultados anteriores los métodos de optimización buscan resolver la **ecuación no lineal** $\\nabla f_o(x)=0$. Dependiendo del número de soluciones de la ecuación $\\nabla f_o(x)=0$ se tienen situaciones distintas. Por ejemplo, si no tiene solución entonces el/los óptimos no se alcanza(n) pues el problema puede no ser acotado por debajo o si existe el óptimo éste puede no alcanzarse. Por otro lado, si la ecuación tiene múltiples soluciones entonces cada solución es un mínimo de $f_o$.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función fuertemente convexa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Definición\n",
    "\n",
    "Una función $f:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ tal que $f \\in \\mathcal{C}^2(\\text{dom}f)$ se nombra **fuertemente convexa** en el conjunto convexo $\\mathbb{S} \\neq \\emptyset$ si existe $m>0$ tal que $\\nabla^2 f(x) - mI$ es simétrica semidefinida positiva $\\forall x \\in \\mathbb{S}$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Comentarios\n",
    "\n",
    "Si una función es fuertemente convexa se puede probar que:\n",
    "\n",
    "* El conjunto óptimo contiene a lo más un punto.\n",
    "\n",
    "\n",
    "* $f(y) \\geq f(x) + \\nabla f(x)^T(y-x) + \\frac{m}{2}||y-x||_2^2 \\forall x,y \\in \\mathbb{S}$. Por esto si $f$ es fuertemente convexa en $\\mathbb{S}$ entonces es estrictamente convexa en $\\mathbb{S}$. También esta desigualdad indica que la diferencia entre la función de $y$, $f(y)$, y la función lineal en $y$ $f(x) + \\nabla f(x)^T(y-x)$ (Taylor a primer orden) está acotada por debajo por una cantidad cuadrática.\n",
    "\n",
    "* El **número de condición** bajo la norma 2 de $\\nabla ^2 f$ está acotado por arriba por el cociente $\\frac{\\lambda_\\text{max}(\\nabla^2 f(x))}{\\lambda_\\text{min}(\\nabla^2 f(x))} \\forall x \\in \\mathbb{S}$.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas de comprehensión.**\n",
    "\n",
    "1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias:**\n",
    "\n",
    "1. S. P. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2009.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
